{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "def calculate_metrics(confusion_matrix):\n",
    "    TP = confusion_matrix[0, 0]  # True Positive\n",
    "    FP = confusion_matrix[0, 1]  # False Positive\n",
    "    FN = confusion_matrix[1, 0]  # False Negative\n",
    "    TN = confusion_matrix[1, 1]  # True Negative\n",
    "\n",
    "    accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "    precision = TP / (TP + FP) if TP + FP != 0 else 0\n",
    "    recall = TP / (TP + FN) if TP + FN != 0 else 0\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall) if precision + recall != 0 else 0\n",
    "    \n",
    "    return accuracy, precision, recall, f1_score\n",
    "\n",
    "\n",
    "\n",
    "dataset_path = 'C:/lsh/learn_sth/data_science_ece/project/data/Covid_dataset.csv'\n",
    "df = pd.read_csv(dataset_path)\n",
    "\n",
    "all_feature_list = ['school','gradelevel','gender','covidpos','householdincome','freelunch','numcomputers','familysize','fathereduc','mothereduc']\n",
    "data_dict = {}\n",
    "for feature in all_feature_list:\n",
    "    data_dict[feature] = df[df['timeperiod']==1][feature].tolist() # 0 or 1\n",
    "\n",
    "all_scores = ['readingscore','writingscore','mathscore','readingscoreSL','writingscoreSL','mathscoreSL']\n",
    "average_score,average_score_InPerson,average_score_Online = [],[],[],\n",
    "\n",
    "for student_id in range(1,1401):\n",
    "    \n",
    "    temp_InPerson = df[(df['studentID']==student_id) & \n",
    "              ((df['timeperiod']==0) | (df['timeperiod']==1) | (df['timeperiod']==2))]\n",
    "    InPerson_mean = temp_InPerson[all_scores].mean(axis=1).mean()\n",
    "    average_score_InPerson.append(InPerson_mean)\n",
    "    \n",
    "    temp_Online = df[(df['studentID']==student_id) & \n",
    "              ((df['timeperiod']==3) | (df['timeperiod']==4) | (df['timeperiod']==5))]\n",
    "    Online_mean = temp_Online[all_scores].mean(axis=1).mean()\n",
    "    average_score_Online.append(Online_mean)\n",
    "    \n",
    "    average_score.append((InPerson_mean+Online_mean)/2)\n",
    "\n",
    "\n",
    "data_dict['average_score'] = average_score\n",
    "data_dict['average_score_InPerson'] = average_score_InPerson\n",
    "data_dict['average_score_Online'] = average_score_Online\n",
    "    \n",
    "    \n",
    "data = pd.DataFrame(data_dict)\n",
    "\n",
    "# Features and target\n",
    "outputs = ['average_score','average_score_InPerson','average_score_Online']\n",
    "\n",
    "X = data.drop(columns=outputs)\n",
    "p = 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression on average_score_InPerson. Training MSE: 12.039259588124851 , R2: 0.758957475384178, RSS: 3370.9926846749586, RSE: 1.5528350289365078\n",
      "Regression on average_score_InPerson. Testing MSE: 14.336904553052806 , R2: 0.7257805334572807, RSS: 4014.3332748547855, RSE: 1.6945450803161708\n"
     ]
    }
   ],
   "source": [
    "# decision tree regression\n",
    "from sklearn.tree import plot_tree\n",
    "\n",
    "outputs = ['average_score_InPerson','average_score_Online']\n",
    "\n",
    "for output in outputs:\n",
    "    if output == 'average_score_InPerson':\n",
    "        before_after = 'before'\n",
    "    else:\n",
    "        before_after = 'after'\n",
    "    \n",
    "    y = data[output]\n",
    "    \n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    tree = DecisionTreeRegressor(random_state=42)\n",
    "    path = tree.cost_complexity_pruning_path(X_train, y_train)\n",
    "    ccp_alphas = path.ccp_alphas  \n",
    "    \n",
    "    tree_cv = GridSearchCV(DecisionTreeRegressor(random_state=42), param_grid={'ccp_alpha': ccp_alphas}, cv=5)\n",
    "    tree_cv.fit(X_train, y_train)\n",
    "    best_alpha = tree_cv.best_params_['ccp_alpha']\n",
    "    # print('the best alpha selected by cross validation is: {}'.format(best_alpha))\n",
    "    \n",
    "    prunned_tree = DecisionTreeRegressor(random_state=42, ccp_alpha=best_alpha)\n",
    "    prunned_tree.fit(X_train, y_train)\n",
    "    \n",
    "    \n",
    "    y_pred = prunned_tree.predict(X_train)\n",
    "    mse = mean_squared_error(y_train, y_pred)\n",
    "    r2 = r2_score(y_train, y_pred)\n",
    "    rss = mse * len(y_test)\n",
    "    rse = np.sqrt(rss / (1400 - p - 1))\n",
    "\n",
    "    print(\"Regression on {}. Training MSE: {} , R2: {}, RSS: {}, RSE: {}\".format(output,mse,r2, rss, rse))\n",
    "    \n",
    "    \n",
    "    # Make predictions on the test data\n",
    "    y_pred = prunned_tree.predict(X_test)\n",
    "    \n",
    "    # Evaluate the model using Mean Squared Error\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    rss = mse * len(y_test)\n",
    "    rse = np.sqrt(rss / (1400 - p - 1))\n",
    "\n",
    "    print(\"Regression on {}. Testing MSE: {} , R2: {}, RSS: {}, RSE: {}\".format(output,mse,r2, rss, rse))\n",
    "    \n",
    "\n",
    "    # plotting the precition vs gt    \n",
    "    # plt.figure(figsize=(8, 6))\n",
    "    # plt.scatter(y_test, y_pred, color='blue', alpha=0.6, label='Predicted vs Actual')\n",
    "    # # plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='red', lw=2, label='Ideal Fit')  # Diagonal line\n",
    "    # plt.plot([30,100], [30,100], color='red', lw=2, label='Ideal Fit')  # Diagonal line\n",
    "    # plt.xlabel('Actual Values (y_test)')\n",
    "    # plt.ylabel('Predicted Values (y_pred)')\n",
    "    # plt.xlim([30,100])\n",
    "    # plt.ylim([30,100])\n",
    "    # plt.title('Decision Tree Regressor: Actual vs Predicted Values (average score {} lockdown)'.format(before_after))\n",
    "    # plt.legend()\n",
    "    # plt.grid(True)\n",
    "    # plt.savefig('DecisionTree_{}Lockdown.jpg'.format(before_after))\n",
    "    # plt.clf()\n",
    "\n",
    "\n",
    "    # plotting the decision treee\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plot_tree(prunned_tree, filled=True,feature_names=['School', 'GL', 'Gender', 'Covid', 'Income',\n",
    "       'Lunch', 'PC', 'FS', 'FE', 'ME'], \n",
    "               impurity=False,       # 不显示 impurity 信息\n",
    "               proportion=False,     # 不显示样本比例信息\n",
    "               label='none')\n",
    "    #['school', 'gradelevel', 'gender', 'covidpos', 'householdincome','freelunch', 'numcomputers', 'familysize', 'fathereduc', 'mothereduc']\n",
    "    # plt.show()\n",
    "    plt.savefig('DecisionTree_{}Lockdown.jpg'.format(before_after),dpi=300)\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "Regression on average_score_InPerson. Training MSE: 9.790675977060294 , R2: 0.8039772098996941, RSS: 2741.3892735768823, RSE: 1.4003344362389996\n",
      "Regression on average_score_InPerson. Testing MSE: 13.709955319417842 , R2: 0.7377720818253793, RSS: 3838.7874894369957, RSE: 1.6570799008739865\n",
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "Regression on average_score_Online. Training MSE: 9.569270471192787 , R2: 0.8055904816895626, RSS: 2679.3957319339806, RSE: 1.3844103737434414\n",
      "Regression on average_score_Online. Testing MSE: 13.052593477684734 , R2: 0.7398362185480678, RSS: 3654.7261737517256, RSE: 1.6168652829379593\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for output in outputs:\n",
    "    \n",
    "    if output == 'average_score_InPerson':\n",
    "        before_after = 'before'\n",
    "    else:\n",
    "        before_after = 'after'\n",
    "        \n",
    "    y = data[output]\n",
    "    \n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    tree = RandomForestRegressor(random_state=42)\n",
    "    \n",
    "    param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [5, 10, 20, 30], #[None, 10, 20, 30]\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    # 'bootstrap': [True, False]\n",
    "    }\n",
    "    \n",
    "    grid_search = GridSearchCV(estimator=tree, param_grid=param_grid, cv=5, n_jobs=1, verbose=1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    best_model = grid_search.best_estimator_\n",
    "\n",
    "    best_model.fit(X_train, y_train)\n",
    "    \n",
    "    \n",
    "    y_pred = best_model.predict(X_train)\n",
    "    mse = mean_squared_error(y_train, y_pred)\n",
    "    r2 = r2_score(y_train, y_pred)\n",
    "    rss = mse * len(y_test)\n",
    "    rse = np.sqrt(rss / (1400 - p - 1))\n",
    "\n",
    "    print(\"Regression on {}. Training MSE: {} , R2: {}, RSS: {}, RSE: {}\".format(output,mse,r2, rss, rse))\n",
    "    \n",
    "    \n",
    "    # Make predictions on the test data\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    \n",
    "    # Evaluate the model using Mean Squared Error\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    rss = mse * len(y_test)\n",
    "    rse = np.sqrt(rss / (1400 - p - 1))\n",
    "\n",
    "    print(\"Regression on {}. Testing MSE: {} , R2: {}, RSS: {}, RSE: {}\".format(output,mse,r2, rss, rse))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    feature_importances = best_model.feature_importances_\n",
    "\n",
    "    importance_df = pd.DataFrame({\n",
    "        'Feature': X.columns,\n",
    "        'Importance': feature_importances\n",
    "    }).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.bar(importance_df['Feature'], importance_df['Importance'], color='skyblue')\n",
    "    plt.title('Feature Importance in Random Forest', fontsize=14)\n",
    "    plt.xlabel('Features', fontsize=12)\n",
    "    plt.ylabel('Importance', fontsize=12)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('RandomForest_{}Lockdown.jpg'.format(before_after))\n",
    "    plt.clf()\n",
    "\n",
    "    # plotting the precition vs gt  \n",
    "    # plt.figure(figsize=(8, 6))\n",
    "    # plt.scatter(y_test, y_pred, color='blue', alpha=0.6, label='Predicted vs Actual')\n",
    "    # # plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='red', lw=2, label='Ideal Fit')  # Diagonal line\n",
    "    # plt.plot([30,100], [30,100], color='red', lw=2, label='Ideal Fit')  # Diagonal line\n",
    "    # plt.xlabel('Actual Values (y_test)')\n",
    "    # plt.ylabel('Predicted Values (y_pred)')\n",
    "    # plt.title('Random Forest Regressor: Actual vs Predicted Values (average score {} lockdown)'.format(before_after))\n",
    "    # plt.legend()\n",
    "    # plt.xlim([30,100])\n",
    "    # plt.ylim([30,100])\n",
    "    # plt.grid(True)\n",
    "    # plt.savefig('RandomForest_{}Lockdown.jpg'.format(before_after))\n",
    "    # plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
      "Confusion matrix for average_score_InPerson\n",
      "[[121  15]\n",
      " [ 16 128]]\n",
      "accuracy:0.8892857142857142, precision:0.8897058823529411, recall:0.8832116788321168, f1:0.8864468864468864\n",
      "\n",
      "\n",
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
      "Confusion matrix for average_score_Online\n",
      "[[133  12]\n",
      " [ 15 120]]\n",
      "accuracy:0.9035714285714286, precision:0.9172413793103448, recall:0.8986486486486487, f1:0.9078498293515358\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "for output in outputs:\n",
    "    y = np.array(data[output]>np.mean(data[output])).astype(int)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=5) #10\n",
    "    \n",
    "    \n",
    "    clf = DecisionTreeClassifier(random_state=42) #42\n",
    "    clf.fit(X_train, y_train)\n",
    "    param_grid = {\n",
    "        'max_depth': [3, 5, 7, None],  # Maximum depth of the tree\n",
    "        'min_samples_split': [2, 10, 20],  # Minimum number of samples required to split a node\n",
    "        'min_samples_leaf': [1, 5, 10],  # Minimum number of samples required at a leaf node\n",
    "        'criterion': ['gini', 'entropy']  # The function to measure the quality of a split\n",
    "    }\n",
    "    grid_search = GridSearchCV(clf, param_grid, cv=5, scoring='accuracy', n_jobs=1, verbose=1)\n",
    "\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    best_model = grid_search.best_estimator_\n",
    "    \n",
    "    \n",
    "\n",
    "    best_model.fit(X_train, y_train)\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    # y_pred = clf.predict(X_test)\n",
    "\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "\n",
    "    print('Confusion matrix for {}'.format(output))\n",
    "    print(cm)\n",
    "    accuracy, precision, recall, f1 = calculate_metrics(cm)\n",
    "    print('accuracy:{}, precision:{}, recall:{}, f1:{}'.format(accuracy, precision, recall, f1))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 216 candidates, totalling 1080 fits\n",
      "Confusion matrix for average_score_InPerson\n",
      "[[131   5]\n",
      " [ 17 127]]\n",
      "accuracy:0.9214285714285714, precision:0.9632352941176471, reacall:0.8851351351351351, f1:0.9225352112676056\n",
      "\n",
      "\n",
      "{'criterion': 'entropy', 'max_depth': 7, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 10}\n",
      "Fitting 5 folds for each of 216 candidates, totalling 1080 fits\n",
      "Confusion matrix for average_score_Online\n",
      "[[133  12]\n",
      " [ 14 121]]\n",
      "accuracy:0.9071428571428571, precision:0.9172413793103448, reacall:0.9047619047619048, f1:0.910958904109589\n",
      "\n",
      "\n",
      "{'criterion': 'gini', 'max_depth': 5, 'min_samples_leaf': 5, 'min_samples_split': 20, 'n_estimators': 10}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for output in outputs:\n",
    "    y = np.array(data[output]>np.mean(data[output])).astype(int)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=5) #10\n",
    "    \n",
    "    clf = RandomForestClassifier(random_state=42)\n",
    "    clf.fit(X_train, y_train)\n",
    "    param_grid = {\n",
    "        'n_estimators': [10, 50, 100],  # Number of trees in the forest\n",
    "        'max_depth': [3, 5, 7, None],  # Maximum depth of the tree\n",
    "        'min_samples_split': [2, 10, 20],  # Minimum number of samples required to split a node\n",
    "        'min_samples_leaf': [1, 5, 10],  # Minimum number of samples required at a leaf node\n",
    "        'criterion': ['gini', 'entropy']  # The function to measure the quality of a split\n",
    "    }\n",
    "    grid_search = GridSearchCV(clf, param_grid, cv=5, scoring='accuracy', n_jobs=1, verbose=1)\n",
    "\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    best_model = grid_search.best_estimator_\n",
    "    \n",
    "\n",
    "    best_model.fit(X_train, y_train)\n",
    "    y_pred = best_model.predict(X_test)\n",
    "\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "        \n",
    "\n",
    "    print('Confusion matrix for {}'.format(output))\n",
    "    print(cm)\n",
    "    accuracy, precision, recall, f1 = calculate_metrics(cm)\n",
    "    print('accuracy:{}, precision:{}, reacall:{}, f1:{}'.format(accuracy, precision, recall, f1))\n",
    "    print(\"\\n\")\n",
    "    print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "Confusion matrix for average_score_InPerson\n",
      "[[113  16]\n",
      " [ 26 125]]\n",
      "accuracy:0.85, precision:0.875968992248062, reacall:0.8129496402877698, f1:0.8432835820895523\n",
      "\n",
      "\n",
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "Confusion matrix for average_score_Online\n",
      "[[113  13]\n",
      " [ 23 131]]\n",
      "accuracy:0.8714285714285714, precision:0.8968253968253969, reacall:0.8308823529411765, f1:0.8625954198473282\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for output in outputs:\n",
    "    y = np.array(data[output]>np.mean(data[output])).astype(int)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    clf = SVC(random_state=42)\n",
    "    param_grid = {\n",
    "        'C': [0.1, 1, 10],  # Regularization parameter\n",
    "        'kernel': ['rbf', 'poly', 'sigmoid'],  # Type of kernel 'linear' is too slow\n",
    "        # 'gamma': ['scale', 'auto'],  # Kernel coefficient for 'rbf', 'poly', and 'sigmoid'\n",
    "        # 'class_weight': [None, 'balanced']  # Class weight adjustment\n",
    "    }\n",
    "    grid_search = GridSearchCV(clf, param_grid, cv=5, scoring='accuracy', n_jobs=1, verbose=1)\n",
    "\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    best_model = grid_search.best_estimator_\n",
    "    \n",
    "    \n",
    "\n",
    "    best_model.fit(X_train, y_train)\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    # y_pred = clf.predict(X_test)\n",
    "\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "        \n",
    "    print('Confusion matrix for {}'.format(output))\n",
    "    print(cm)\n",
    "    accuracy, precision, recall, f1 = calculate_metrics(cm)\n",
    "    print('accuracy:{}, precision:{}, reacall:{}, f1:{}'.format(accuracy, precision, recall, f1))\n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
